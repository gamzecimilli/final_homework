# ============================================================
# Chest X-Ray (NORMAL vs PNEUMONIA) - GeliÅŸtirilmiÅŸ Ã‡oklu Deney Pipeline v2
# ============================================================
# 
# YENÄ° Ã–ZELLÄ°KLER (v2):
# ----------------------
# 1. AkÄ±llÄ± Model Kaydetme:
#    - Model adÄ± + balanced accuracy + epoch numarasÄ± ile isimlendirme
#    - Her model kendi klasÃ¶rÃ¼nde: output_dir/model_name/scenario_xxx/
#    - Otomatik isimlendirme (grid boyutu deÄŸiÅŸse bile)
#
# 2. 3 Seviyeli Augmentasyon:
#    - none: Augmentasyon yok (sadece resize + crop)
#    - medium: Orta seviye (flip + rotation + hafif renk)
#    - strong: Zengin augmentasyon (elastic, CLAHE simÃ¼lasyonu, vs.)
#
# 3. Modern PyTorch API:
#    - torch.amp (yeni mixed precision API)
#    - Gradient clipping
#    - CosineAnnealingWarmRestarts scheduler
#
# 4. DetaylÄ± Loglama:
#    - Her epoch: train_loss, val_balanced_acc
#    - En iyi model iÃ§in: test balanced_acc, F1, sensitivity, specificity
#    - AyrÄ± Excel dosyasÄ±: kaydedilen modelin tÃ¼m parametreleri
#
# 5. Otomatik KlasÃ¶r YapÄ±sÄ±:
#    - output_dir/
#      â”œâ”€â”€ efficientnet_b1/
#      â”‚   â”œâ”€â”€ sz512_aug_strong/
#      â”‚   â”‚   â”œâ”€â”€ efficientnet_b1_ep05_balacc0.9234_BEST.pth
#      â”‚   â”‚   â”œâ”€â”€ training_log.xlsx
#      â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
#      â”‚   â”‚   â””â”€â”€ gradcam/
#      â”‚   â””â”€â”€ sz224_aug_none/
#      â”œâ”€â”€ mobilenet_v3_large/
#      â””â”€â”€ experiments_summary.xlsx
#
# ============================================================

# %% =====================================================
# IMPORTS - Gerekli KÃ¼tÃ¼phaneler
# ========================================================
import os
import time
import math
import copy
import random
import warnings
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Tuple, Optional, Literal
from datetime import datetime

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler
from torchvision import transforms, models
from PIL import Image, ImageFilter, ImageEnhance
from torchvision import models
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import (
    accuracy_score, balanced_accuracy_score, f1_score, 
    precision_score, recall_score, confusion_matrix, roc_auc_score
)

# UyarÄ±larÄ± bastÄ±r (temiz Ã§Ä±ktÄ± iÃ§in)
warnings.filterwarnings('ignore', category=UserWarning)

# Grad-CAM (opsiyonel - yÃ¼klÃ¼ deÄŸilse otomatik devre dÄ±ÅŸÄ±)
try:
    from pytorch_grad_cam import GradCAM
    from pytorch_grad_cam.utils.image import show_cam_on_image
    GRADCAM_AVAILABLE = True
except ImportError:
    GRADCAM_AVAILABLE = False
    print("âš ï¸ Grad-CAM paketi yÃ¼klÃ¼ deÄŸil. GÃ¶rselleÅŸtirme devre dÄ±ÅŸÄ±.")
    print("   YÃ¼klemek iÃ§in: pip install grad-cam")


# %% =====================================================
# CONFIGURATION - TÃ¼m Ayarlar Tek Yerde
# ========================================================
# 
# Bu bÃ¶lÃ¼mde tÃ¼m deney parametrelerini deÄŸiÅŸtirebilirsiniz.
# Grid boyutlarÄ± deÄŸiÅŸse bile isimlendirme otomatik yapÄ±lÄ±r.
# ========================================================

CONFIG = {
    # ----- VERÄ° AYARLARI -----
    # dataset_root: NORMAL ve PNEUMONIA klasÃ¶rlerini iÃ§eren ana dizin
    # Ã–rnek yapÄ±:
    #   /path/to/chest_xray/
    #   â”œâ”€â”€ NORMAL/
    #   â”‚   â”œâ”€â”€ img001.jpg
    #   â”‚   â””â”€â”€ ...
    #   â””â”€â”€ PNEUMONIA/
    #       â”œâ”€â”€ img001.jpg
    #       â””â”€â”€ ...
    "dataset_root": r"chest_full",  #
    "class_names": ["NORMAL", "PNEUMONIA"],       # KlasÃ¶r adlarÄ± (sÄ±ra Ã¶nemli: 0=NORMAL, 1=PNEUMONIA)

    # ----- VERÄ° BÃ–LME AYARLARI -----
    # Stratified split: Her sÄ±nÄ±ftan orantÄ±lÄ± Ã¶rnek alÄ±nÄ±r
    "split": {
        "train_ratio": 0.75,  # EÄŸitim verisi oranÄ±
        "val_ratio":   0.15,  # DoÄŸrulama verisi oranÄ±  
        "test_ratio":  0.10,  # Test verisi oranÄ±
        "seed": 42,           # Tekrarlanabilirlik iÃ§in sabit seed
    },

    # ----- DENEY GRID'Ä° -----
    # TÃ¼m kombinasyonlar otomatik denenir
    # Ã–rnek: 3 boyut Ã— 4 model Ã— 3 aug = 36 deney
    "experiments": {
        # GÃ¶rÃ¼ntÃ¼ boyutlarÄ± (bÃ¼yÃ¼k boyut = daha fazla detay, daha yavaÅŸ)
        "input_sizes": [512, 256],
        
        # Test edilecek modeller
        "models": [
            "efficientnet_b1",      # Dengeli performans/hÄ±z
            "mobilenet_v3_large",   # HÄ±zlÄ±, mobil uyumlu
            "densenet121",
        ],
        
        # Augmentasyon seviyeleri (3 seviye)
        # "none": Sadece resize + center crop
        # "medium": Flip + rotation + hafif brightness
        # "strong": YukarÄ±dakiler + blur + contrast + affine
        "augmentation_levels": ["none", "medium", "strong"],
    },

    # ----- EÄÄ°TÄ°M AYARLARI -----
    "train": {
        "batch_size": 32,        # GPU belleÄŸine gÃ¶re ayarla (512px iÃ§in 8-16)
        "num_epochs": 25,        # Maksimum epoch (early stopping var)
        "patience": 7,           # Bu kadar epoch iyileÅŸme olmazsa dur
        "learning_rate": 1e-3,   # BaÅŸlangÄ±Ã§ Ã¶ÄŸrenme oranÄ±
        "weight_decay": 1e-4,    # L2 regularization
        "num_workers": 4,        # DataLoader paralel iÅŸÃ§i sayÄ±sÄ±
        "label_smoothing": 0.1,  # Label smoothing (0.0-0.2 arasÄ±)
    },

    # ----- LEARNING RATE SCHEDULER -----
    # CosineAnnealingWarmRestarts: Periyodik olarak LR'Ä± sÄ±fÄ±rlar
    "scheduler": {
        "type": "cosine_warm_restarts",  # "cosine_warm_restarts" veya "cosine_annealing"
        "T_0": 10,                        # Ä°lk restart periyodu (epoch)
        "T_mult": 2,                      # Her restart'ta periyod Ã§arpanÄ±
        "eta_min": 1e-5,                  # Minimum Ã¶ÄŸrenme oranÄ±
    },

    # ----- MIXED PRECISION (AMP) -----
    # GPU'da eÄŸitimi 1.5-2x hÄ±zlandÄ±rÄ±r, bellek tasarrufu saÄŸlar
    "amp": {
        "enabled": True,  # CUDA yoksa otomatik devre dÄ±ÅŸÄ±
    },

    # ----- SINIF DENGESÄ°ZLÄ°ÄÄ° -----
    # WeightedRandomSampler: Az olan sÄ±nÄ±ftan daha sÄ±k Ã¶rnekleme
    "imbalance": {
        "use_weighted_sampler": True,
    },

    # ----- Ã‡IKTI AYARLARI -----
    "output": {
        "save_dir": "out_chest_v1.1",          # Ana Ã§Ä±ktÄ± klasÃ¶rÃ¼
        "save_torchscript": True,               # TorchScript formatÄ±nda kaydet (.pt)
        "save_confusion_matrix": True,          # Confusion matrix PNG
        "save_training_curves": True,           # Loss/accuracy grafikleri
        "export_model_params_excel": True,      # Her model iÃ§in parametre Excel'i
    },

    # ----- GRAD-CAM AYARLARI -----
    "gradcam": {
        "enabled": True,          # Grad-CAM gÃ¶rselleÅŸtirmesi
        "num_samples": 8,         # Test setinden kaÃ§ Ã¶rnek
    },
}

# ImageNet normalizasyon deÄŸerleri (pretrained modeller iÃ§in)
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

# %% =====================================================
# YARDIMCI FONKSÄ°YONLAR
# ========================================================

def seed_everything(seed: int) -> None:
    """
    TÃ¼m random seed'leri sabitler.
    Bu sayede aynÄ± seed ile aynÄ± sonuÃ§lar elde edilir (reproducibility).
    
    Args:
        seed: Sabitlenecek seed deÄŸeri
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # Deterministik mod (biraz yavaÅŸlatÄ±r ama sonuÃ§lar tutarlÄ±)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def get_device() -> torch.device:
    """
    KullanÄ±labilir en iyi cihazÄ± dÃ¶ndÃ¼rÃ¼r.
    CUDA > MPS (Apple Silicon) > CPU
    
    Returns:
        torch.device: KullanÄ±lacak cihaz
    """
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"âœ“ GPU bulundu: {torch.cuda.get_device_name(0)}")
        print(f"  Bellek: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device("mps")
        print("âœ“ Apple Silicon GPU (MPS) kullanÄ±lÄ±yor")
    else:
        device = torch.device("cpu")
        print("âš ï¸ GPU bulunamadÄ±, CPU kullanÄ±lÄ±yor (yavaÅŸ olacak)")
    return device


def format_time(seconds: float) -> str:
    """Saniyeyi okunabilir formata Ã§evirir (1h 23m 45s)"""
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    
    if h > 0:
        return f"{h}h {m}m {s}s"
    elif m > 0:
        return f"{m}m {s}s"
    else:
        return f"{s}s"


def create_experiment_name(model_name: str, input_size: int, aug_level: str) -> str:
    """
    Deney iÃ§in benzersiz ve okunabilir isim oluÅŸturur.
    
    Ã–rnek: "efficientnet_b1_sz224_aug_medium"
    
    Args:
        model_name: Model adÄ±
        input_size: GÃ¶rÃ¼ntÃ¼ boyutu
        aug_level: Augmentasyon seviyesi
    
    Returns:
        str: Deney adÄ±
    """
    return f"{model_name}_sz{input_size}_aug_{aug_level}"


def create_model_filename(model_name: str, epoch: int, bal_acc: float, 
                          input_size: int, aug_level: str, suffix: str = "") -> str:
    """
    Kaydedilecek model iÃ§in detaylÄ± dosya adÄ± oluÅŸturur.
    
    Ã–rnek: "efficientnet_b1_sz224_aug_medium_ep05_balacc0.9234_BEST.pth"
    
    Args:
        model_name: Model adÄ±
        epoch: Epoch numarasÄ±
        bal_acc: Balanced accuracy deÄŸeri
        input_size: GÃ¶rÃ¼ntÃ¼ boyutu
        aug_level: Augmentasyon seviyesi
        suffix: Ek bilgi (BEST, LAST, vs.)
    
    Returns:
        str: Dosya adÄ±
    """
    base = f"{model_name}_sz{input_size}_aug_{aug_level}"
    metrics = f"ep{epoch:02d}_balacc{bal_acc:.4f}"
    
    if suffix:
        return f"{base}_{metrics}_{suffix}.pth"
    return f"{base}_{metrics}.pth"


# %% =====================================================
# VERÄ° YÃœKLEYÄ°CÄ° SINIFI
# ========================================================

def list_images(dataset_root: str, class_names: List[str]) -> Tuple[List[str], List[int]]:
    """
    KlasÃ¶rlerden gÃ¶rÃ¼ntÃ¼ dosyalarÄ±nÄ± listeler.
    
    Beklenen yapÄ±:
        dataset_root/
        â”œâ”€â”€ NORMAL/
        â”‚   â”œâ”€â”€ img1.jpg
        â”‚   â””â”€â”€ ...
        â””â”€â”€ PNEUMONIA/
            â”œâ”€â”€ img1.jpg
            â””â”€â”€ ...
    
    Args:
        dataset_root: Veri kÃ¶k dizini
        class_names: SÄ±nÄ±f klasÃ¶r adlarÄ± listesi
    
    Returns:
        Tuple[List[str], List[int]]: (dosya_yollarÄ±, etiketler)
    """
    paths, labels = [], []
    
    valid_extensions = {".jpg", ".jpeg", ".png", ".bmp", ".webp", ".tiff", ".tif"}
    
    for class_idx, class_name in enumerate(class_names):
        class_dir = os.path.join(dataset_root, class_name)
        
        if not os.path.isdir(class_dir):
            raise FileNotFoundError(
                f"âŒ SÄ±nÄ±f klasÃ¶rÃ¼ bulunamadÄ±: {class_dir}\n"
                f"   LÃ¼tfen dataset_root ayarÄ±nÄ± kontrol edin."
            )
        
        # KlasÃ¶rdeki tÃ¼m gÃ¶rÃ¼ntÃ¼leri bul
        count = 0
        for filename in sorted(os.listdir(class_dir)):
            ext = os.path.splitext(filename)[1].lower()
            if ext in valid_extensions:
                paths.append(os.path.join(class_dir, filename))
                labels.append(class_idx)
                count += 1
        
        print(f"  {class_name}: {count} gÃ¶rÃ¼ntÃ¼ bulundu")
    
    if len(paths) == 0:
        raise RuntimeError(
            "âŒ HiÃ§ gÃ¶rÃ¼ntÃ¼ bulunamadÄ±!\n"
            "   KlasÃ¶r yapÄ±sÄ±nÄ± ve dosya uzantÄ±larÄ±nÄ± kontrol edin."
        )
    
    return paths, labels


class ChestXRayDataset(Dataset):
    """
    Chest X-Ray gÃ¶rÃ¼ntÃ¼leri iÃ§in PyTorch Dataset sÄ±nÄ±fÄ±.
    
    Ã–zellikler:
    - GÃ¶rÃ¼ntÃ¼leri RGB'ye Ã§evirir (grayscale olsa bile)
    - Transform uygulanabilir
    - Lazy loading (bellek dostu)
    """
    
    def __init__(self, paths: List[str], labels: List[int], transform=None):
        """
        Args:
            paths: GÃ¶rÃ¼ntÃ¼ dosya yollarÄ±
            labels: SÄ±nÄ±f etiketleri (0 veya 1)
            transform: Uygulanacak dÃ¶nÃ¼ÅŸÃ¼mler
        """
        self.paths = paths
        self.labels = labels
        self.transform = transform
    
    def __len__(self) -> int:
        return len(self.paths)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:
        img_path = self.paths[idx]
        label = self.labels[idx]
        
        # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle ve RGB'ye Ã§evir
        img = Image.open(img_path).convert("RGB")
        
        if self.transform:
            img = self.transform(img)
        
        return img, label


# %% =====================================================
# STRATIFIED SPLIT - Dengeli Veri BÃ¶lme
# ========================================================

def stratified_split(
    paths: List[str], 
    labels: List[int],
    train_ratio: float, 
    val_ratio: float, 
    test_ratio: float,
    seed: int
) -> Tuple[Tuple[List[str], List[int]], ...]:
    """
    Veriyi stratified (katmanlÄ±) olarak train/val/test'e bÃ¶ler.
    
    Stratified: Her bÃ¶lÃ¼mde sÄ±nÄ±f oranlarÄ± korunur.
    Ã–rnek: %70 NORMAL, %30 PNEUMONIA -> Her split'te de aynÄ± oran
    
    Args:
        paths: TÃ¼m gÃ¶rÃ¼ntÃ¼ yollarÄ±
        labels: TÃ¼m etiketler
        train_ratio: EÄŸitim oranÄ± (Ã¶rn: 0.70)
        val_ratio: DoÄŸrulama oranÄ± (Ã¶rn: 0.15)
        test_ratio: Test oranÄ± (Ã¶rn: 0.15)
        seed: Random seed
    
    Returns:
        Tuple: ((train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels))
    """
    # Oran kontrolÃ¼
    total = train_ratio + val_ratio + test_ratio
    assert abs(total - 1.0) < 1e-6, f"Split oranlarÄ± toplamÄ± 1.0 olmalÄ±, ÅŸu an: {total}"
    
    X = np.array(paths)
    y = np.array(labels)
    
    # Ä°lk bÃ¶lme: train vs (val + test)
    sss1 = StratifiedShuffleSplit(
        n_splits=1, 
        test_size=(val_ratio + test_ratio), 
        random_state=seed
    )
    train_idx, temp_idx = next(sss1.split(X, y))
    
    X_train, y_train = X[train_idx], y[train_idx]
    X_temp, y_temp = X[temp_idx], y[temp_idx]
    
    # Ä°kinci bÃ¶lme: val vs test
    test_size_ratio = test_ratio / (val_ratio + test_ratio)
    sss2 = StratifiedShuffleSplit(
        n_splits=1, 
        test_size=test_size_ratio, 
        random_state=seed
    )
    val_idx, test_idx = next(sss2.split(X_temp, y_temp))
    
    X_val, y_val = X_temp[val_idx], y_temp[val_idx]
    X_test, y_test = X_temp[test_idx], y_temp[test_idx]
    
    return (
        (X_train.tolist(), y_train.tolist()),
        (X_val.tolist(), y_val.tolist()),
        (X_test.tolist(), y_test.tolist())
    )


# %% =====================================================
# AUGMENTASYON TRANSFORMS - 3 Seviye
# ========================================================

class RandomGaussianBlur:
    """Rastgele Gaussian blur uygular (X-ray iÃ§in hafif)"""
    def __init__(self, p: float = 0.3, radius_range: Tuple[float, float] = (0.5, 1.5)):
        self.p = p
        self.radius_range = radius_range
    
    def __call__(self, img: Image.Image) -> Image.Image:
        if random.random() < self.p:
            radius = random.uniform(*self.radius_range)
            return img.filter(ImageFilter.GaussianBlur(radius=radius))
        return img


class RandomBrightnessContrast:
    """Rastgele parlaklÄ±k ve kontrast ayarÄ±"""
    def __init__(self, brightness_range: Tuple[float, float] = (0.9, 1.1),
                 contrast_range: Tuple[float, float] = (0.9, 1.1), p: float = 0.5):
        self.brightness_range = brightness_range
        self.contrast_range = contrast_range
        self.p = p
    
    def __call__(self, img: Image.Image) -> Image.Image:
        if random.random() < self.p:
            # ParlaklÄ±k
            brightness_factor = random.uniform(*self.brightness_range)
            img = ImageEnhance.Brightness(img).enhance(brightness_factor)
            
            # Kontrast
            contrast_factor = random.uniform(*self.contrast_range)
            img = ImageEnhance.Contrast(img).enhance(contrast_factor)
        return img



def build_transforms(
    input_size: int, 
    aug_level: Literal["none", "medium", "strong"]
) -> Tuple[transforms.Compose, transforms.Compose, transforms.Compose]:
    """
    X-Ray gÃ¶rÃ¼ntÃ¼leri iÃ§in optimize edilmiÅŸ 3 seviyeli augmentasyon.
    
    Ã–NEMLÄ° X-RAY NOTLARI:
    ---------------------
    - HorizontalFlip DÃœÅÃœK tutulmalÄ±: Kalp sol tarafta, flip anatomik hata yaratÄ±r
    - VerticalFlip KULLANILMAMALI: Anatomik olarak anlamsÄ±z
    - ColorJitter KULLANILMAMALI: X-ray gri tonlamalÄ±, renk deÄŸiÅŸimi anlamsÄ±z
    - Rotasyon SINIRLI tutulmalÄ±: GerÃ§ek Ã§ekimlerde Â±10Â° Ã¼stÃ¼ nadir
    - Agresif crop KULLANILMAMALI: AkciÄŸer kenarlarÄ± kesilmemeli
    
    Seviyeler:
    ---------
    none (yok):
        - Sadece resize ve center crop
        - Baseline / karÅŸÄ±laÅŸtÄ±rma iÃ§in
        - Veri zaten Ã§ok bÃ¼yÃ¼kse yeterli olabilir
    
    medium (orta):
        - Hafif geometrik dÃ¶nÃ¼ÅŸÃ¼mler
        - Hafif parlaklÄ±k/kontrast
        - Genel kullanÄ±m iÃ§in Ã¶nerilen
    
    strong (zengin):
        - Daha fazla varyasyon ama hala konservatif
        - Gaussian blur (dÃ¼ÅŸÃ¼k kalite simÃ¼lasyonu)
        - Veri azsa veya overfitting varsa kullan
    
    Args:
        input_size: Hedef gÃ¶rÃ¼ntÃ¼ boyutu (kare, Ã¶rn: 224, 512)
        aug_level: Augmentasyon seviyesi ("none", "medium", "strong")
    
    Returns:
        Tuple: (train_transform, eval_transform, visualization_transform)
    """
    # Resize boyutu: Crop iÃ§in biraz bÃ¼yÃ¼k tut (%10 fazla)
    resize_size = int(input_size * 1.1)
    
    # =========================================================
    # AUGMENTASYON YOK (Baseline)
    # =========================================================
    # KullanÄ±m: KarÅŸÄ±laÅŸtÄ±rma iÃ§in baseline, bÃ¼yÃ¼k veri setleri
    if aug_level == "none":
        train_tf = transforms.Compose([
            # BoyutlandÄ±rma
            transforms.Resize(resize_size),
            transforms.CenterCrop(input_size),
            
            # Tensor'a Ã§evir ve normalize et
            transforms.ToTensor(),
            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),
        ])
    
    # =========================================================
    # ORTA SEVÄ°YE AUGMENTASYON (Ã–nerilen)
    # =========================================================
    # KullanÄ±m: Ã‡oÄŸu X-ray projesi iÃ§in ideal baÅŸlangÄ±Ã§
    elif aug_level == "medium":
        train_tf = transforms.Compose([
            # BoyutlandÄ±rma
            transforms.Resize(resize_size),
            
            # Hafif random crop: %95-100 oranÄ±nda (kenarlardan az kes)
            transforms.RandomResizedCrop(input_size, scale=(0.95, 1.0)),
            
            # Yatay flip: DÃœÅÃœK olasÄ±lÄ±k (kalp sol tarafta!)
            # p=0.1 â†’ %10 ÅŸansla flip (veya tamamen kaldÄ±rabilirsin)
            transforms.RandomHorizontalFlip(p=0.1),
            
            # Hafif rotasyon: Â±7Â° (gerÃ§ekÃ§i Ã§ekim aÃ§Ä±sÄ± varyasyonu)
            transforms.RandomRotation(degrees=7),
            
            # Hafif parlaklÄ±k/kontrast: FarklÄ± cihaz ayarlarÄ±nÄ± simÃ¼le eder
            RandomBrightnessContrast(
                brightness_range=(0.95, 1.05),  # Â±%5
                contrast_range=(0.95, 1.05),    # Â±%5
                p=0.3  # %30 olasÄ±lÄ±k
            ),
            
            # Tensor'a Ã§evir ve normalize et
            transforms.ToTensor(),
            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),
        ])
    
    # =========================================================
    # ZENGÄ°N AUGMENTASYON (X-Ray iÃ§in Optimize EdilmiÅŸ)
    # =========================================================
    # KullanÄ±m: Veri azsa, overfitting varsa
    # NOT: Genel "strong" augmentasyondan DAHA YUMUÅAK!
    #      X-ray iÃ§in agresif augmentasyon zararlÄ± olabilir.
    elif aug_level == "strong":
        train_tf = transforms.Compose([
            # BoyutlandÄ±rma
            transforms.Resize(resize_size),
            
            # Random crop: %90-100 (biraz daha agresif ama hala konservatif)
            transforms.RandomResizedCrop(input_size, scale=(0.9, 1.0)),
            
            # Yatay flip: Hala dÃ¼ÅŸÃ¼k olasÄ±lÄ±k
            transforms.RandomHorizontalFlip(p=0.1),
            
            # Rotasyon: Â±10Â° (maksimum gÃ¼venli deÄŸer)
            transforms.RandomRotation(degrees=10),
            
            # Affine dÃ¶nÃ¼ÅŸÃ¼mler: Hafif translate, scale, shear
            transforms.RandomAffine(
                degrees=0,               # Rotasyon yukarÄ±da zaten var
                translate=(0.03, 0.03),  # %3 kaydÄ±rma (Ã§ok az)
                scale=(0.97, 1.03),      # %3 Ã¶lÃ§ekleme (Ã§ok az)
                shear=2                  # 2Â° shear (Ã§ok az)
            ),
            
            # Gaussian blur: DÃ¼ÅŸÃ¼k kaliteli gÃ¶rÃ¼ntÃ¼ simÃ¼lasyonu
            RandomGaussianBlur(p=0.15, radius_range=(0.5, 1.0)),
            
            # ParlaklÄ±k/Kontrast: FarklÄ± cihaz/ayar simÃ¼lasyonu
            RandomBrightnessContrast(
                brightness_range=(0.9, 1.1),   # Â±%10
                contrast_range=(0.9, 1.1),     # Â±%10
                p=0.4  # %40 olasÄ±lÄ±k
            ),
            
            # Tensor'a Ã§evir ve normalize et
            transforms.ToTensor(),
            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),
        ])
    
    else:
        raise ValueError(
            f"GeÃ§ersiz aug_level: '{aug_level}'\n"
            f"GeÃ§erli deÄŸerler: 'none', 'medium', 'strong'"
        )
    
    # =========================================================
    # DEÄERLENDÄ°RME TRANSFORM (Val/Test iÃ§in)
    # =========================================================
    # Augmentasyon YOK - Her Ã§alÄ±ÅŸtÄ±rmada aynÄ± sonuÃ§ iÃ§in
    eval_tf = transforms.Compose([
        transforms.Resize(resize_size),
        transforms.CenterCrop(input_size),
        transforms.ToTensor(),
        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),
    ])
    
    # =========================================================
    # GÃ–RSELLEÅTÄ°RME TRANSFORM (Grad-CAM iÃ§in)
    # =========================================================
    # Normalize YOK - Ä°nsan gÃ¶zÃ¼yle gÃ¶rÃ¼ntÃ¼lemek iÃ§in
    vis_tf = transforms.Compose([
        transforms.Resize(resize_size),
        transforms.CenterCrop(input_size),
        transforms.ToTensor(),
        # Normalize yok! GÃ¶rsel Ã§Ä±ktÄ± iÃ§in [0,1] aralÄ±ÄŸÄ±nda kalmalÄ±
    ])
    
    return train_tf, eval_tf, vis_tf


# %% =====================================================
# WEIGHTED SAMPLER - SÄ±nÄ±f DengesizliÄŸi Ã‡Ã¶zÃ¼mÃ¼
# ========================================================

def make_weighted_sampler(
    labels: List[int], 
    num_classes: int
) -> Tuple[WeightedRandomSampler, List[int], List[float]]:
    """
    Dengesiz sÄ±nÄ±flar iÃ§in aÄŸÄ±rlÄ±klÄ± Ã¶rnekleyici oluÅŸturur.
    
    Ã‡alÄ±ÅŸma mantÄ±ÄŸÄ±:
    - Az olan sÄ±nÄ±ftan daha sÄ±k Ã¶rnekleme yapÄ±lÄ±r
    - AÄŸÄ±rlÄ±k = 1 / sÄ±nÄ±f_Ã¶rnek_sayÄ±sÄ±
    - Her batch'te sÄ±nÄ±f daÄŸÄ±lÄ±mÄ± daha dengeli olur
    
    Args:
        labels: EÄŸitim etiketleri
        num_classes: SÄ±nÄ±f sayÄ±sÄ±
    
    Returns:
        Tuple: (sampler, sÄ±nÄ±f_sayÄ±larÄ±, sÄ±nÄ±f_aÄŸÄ±rlÄ±klarÄ±)
    """
    labels_arr = np.array(labels)
    
    # Her sÄ±nÄ±ftan kaÃ§ Ã¶rnek var?
    class_counts = np.bincount(labels_arr, minlength=num_classes)
    
    # SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± (ters orantÄ±lÄ±)
    class_weights = 1.0 / np.maximum(class_counts, 1)  # 0'a bÃ¶lme korumasÄ±
    
    # Her Ã¶rnek iÃ§in aÄŸÄ±rlÄ±k
    sample_weights = class_weights[labels_arr]
    sample_weights = torch.tensor(sample_weights, dtype=torch.double)
    
    # WeightedRandomSampler: AÄŸÄ±rlÄ±klara gÃ¶re Ã¶rnekleme
    sampler = WeightedRandomSampler(
        weights=sample_weights,
        num_samples=len(sample_weights),
        replacement=True  # AynÄ± Ã¶rnek birden fazla seÃ§ilebilir
    )
    
    return sampler, class_counts.tolist(), class_weights.tolist()


# %% =====================================================
# MODEL BUILDER - Pretrained Model OluÅŸturma
# ========================================================



def build_model(model_name: str, num_classes: int = 2, pretrained: bool = True) -> nn.Module:
    model_name = model_name.lower().strip()

    if model_name == "efficientnet_b1":
        weights = models.EfficientNet_B1_Weights.IMAGENET1K_V1 if pretrained else None
        model = models.efficientnet_b1(weights=weights)
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(in_features, num_classes)

    elif model_name == "mobilenet_v3_large":
        weights = models.MobileNet_V3_Large_Weights.IMAGENET1K_V1 if pretrained else None
        model = models.mobilenet_v3_large(weights=weights)
        in_features = model.classifier[3].in_features
        model.classifier[3] = nn.Linear(in_features, num_classes)

    elif model_name == "densenet121":
        weights = models.DenseNet121_Weights.IMAGENET1K_V1 if pretrained else None
        model = models.densenet121(weights=weights)
        in_features = model.classifier.in_features
        model.classifier = nn.Linear(in_features, num_classes)

    elif model_name == "vgg16_bn":
        weights = models.VGG16_BN_Weights.IMAGENET1K_V1 if pretrained else None
        model = models.vgg16_bn(weights=weights)
        in_features = model.classifier[6].in_features
        model.classifier[6] = nn.Linear(in_features, num_classes)

    else:
        raise ValueError("...")

    return model



def count_parameters(model: nn.Module) -> Tuple[int, int]:
    """
    Model parametre sayÄ±sÄ±nÄ± hesaplar.
    
    Returns:
        Tuple: (toplam_parametre, eÄŸitilebilir_parametre)
    """
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total, trainable


# %% =====================================================
# METRÄ°K HESAPLAMA
# ========================================================

def compute_binary_metrics(
    probs: np.ndarray, 
    preds: np.ndarray, 
    targets: np.ndarray
) -> Dict:
    """
    Ä°kili sÄ±nÄ±flandÄ±rma metrikleri hesaplar.
    
    Hesaplanan metrikler:
    - Accuracy: DoÄŸru tahmin oranÄ±
    - Balanced Accuracy: SÄ±nÄ±f dengesizliÄŸine dayanÄ±klÄ± accuracy
    - F1 Score: Precision ve Recall harmonik ortalamasÄ±
    - Precision: Pozitif tahminlerin doÄŸruluÄŸu
    - Recall (Sensitivity): GerÃ§ek pozitifleri yakalama oranÄ±
    - Specificity: GerÃ§ek negatifleri yakalama oranÄ±
    - ROC-AUC: ROC eÄŸrisi altÄ±ndaki alan
    
    Args:
        probs: Softmax olasÄ±lÄ±klarÄ± (N, 2)
        preds: Tahmin edilen sÄ±nÄ±flar (N,)
        targets: GerÃ§ek etiketler (N,)
    
    Returns:
        Dict: TÃ¼m metrikler + confusion matrix
    """
    # Temel metrikler
    acc = accuracy_score(targets, preds)
    bal_acc = balanced_accuracy_score(targets, preds)
    f1 = f1_score(targets, preds, average='binary')
    precision = precision_score(targets, preds, average='binary', zero_division=0)
    recall = recall_score(targets, preds, average='binary', zero_division=0)  # Sensitivity
    
    # Confusion matrix'ten specificity hesapla
    cm = confusion_matrix(targets, preds)
    # cm[0,0] = TN, cm[0,1] = FP, cm[1,0] = FN, cm[1,1] = TP
    tn, fp, fn, tp = cm.ravel()
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0
    
    # ROC-AUC (pozitif sÄ±nÄ±f olasÄ±lÄ±ÄŸÄ± ile)
    try:
        roc_auc = roc_auc_score(targets, probs[:, 1])
    except Exception:
        roc_auc = float('nan')
    
    return {
        'accuracy': acc,
        'balanced_accuracy': bal_acc,
        'f1_score': f1,
        'precision': precision,
        'recall': recall,           # = Sensitivity
        'sensitivity': recall,      # AynÄ± ÅŸey, aÃ§Ä±k isim
        'specificity': specificity,
        'roc_auc': roc_auc,
        'confusion_matrix': cm,
        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp
    }


@torch.no_grad()
def predict_with_probs(
    model: nn.Module, 
    loader: DataLoader, 
    device: torch.device,
    use_amp: bool
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Model ile tahmin yapar ve olasÄ±lÄ±klarÄ± dÃ¶ndÃ¼rÃ¼r.
    
    Args:
        model: EÄŸitilmiÅŸ model
        loader: DataLoader
        device: Cihaz
        use_amp: Mixed precision kullan
    
    Returns:
        Tuple: (olasÄ±lÄ±klar, tahminler, gerÃ§ek_etiketler)
    """
    model.eval()
    
    all_probs = []
    all_preds = []
    all_targets = []
    
    for images, labels in loader:
        images = images.to(device)
        labels = labels.to(device)
        
        # Mixed precision forward
        with torch.amp.autocast(device_type=device.type, enabled=use_amp):
            logits = model(images)
            probs = torch.softmax(logits, dim=1)
        
        preds = probs.argmax(dim=1)
        
        all_probs.append(probs.cpu())
        all_preds.append(preds.cpu())
        all_targets.append(labels.cpu())
    
    # BirleÅŸtir
    all_probs = torch.cat(all_probs, dim=0).numpy()
    all_preds = torch.cat(all_preds, dim=0).numpy()
    all_targets = torch.cat(all_targets, dim=0).numpy()
    
    return all_probs, all_preds, all_targets


# %% =====================================================
# GÃ–RSELLEÅTÄ°RME FONKSÄ°YONLARI
# ========================================================

def save_confusion_matrix_plot(
    cm: np.ndarray, 
    class_names: List[str], 
    save_path: str, 
    title: str = "Confusion Matrix"
) -> None:
    """
    Confusion matrix'i PNG olarak kaydeder.
    
    Args:
        cm: Confusion matrix (2x2)
        class_names: SÄ±nÄ±f isimleri
        save_path: KayÄ±t yolu
        title: Grafik baÅŸlÄ±ÄŸÄ±
    """
    plt.figure(figsize=(6, 5))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(title, fontsize=12)
    plt.colorbar()
    
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names, rotation=45, ha='right')
    plt.yticks(tick_marks, class_names)
    
    # HÃ¼cre deÄŸerlerini yaz
    thresh = cm.max() / 2.0
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], 'd'),
                    ha='center', va='center',
                    color='white' if cm[i, j] > thresh else 'black',
                    fontsize=14)
    
    plt.ylabel('GerÃ§ek Etiket', fontsize=11)
    plt.xlabel('Tahmin', fontsize=11)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()


def save_training_curves(
    history: List[Dict], 
    save_path: str, 
    title: str = "Training Curves"
) -> None:
    """
    EÄŸitim eÄŸrilerini (loss, accuracy) PNG olarak kaydeder.
    
    Args:
        history: Epoch bazlÄ± metrik listesi
        save_path: KayÄ±t yolu
        title: Grafik baÅŸlÄ±ÄŸÄ±
    """
    epochs = [h['epoch'] for h in history]
    train_loss = [h['train_loss'] for h in history]
    val_loss = [h.get('val_loss', 0) for h in history]
    train_bal_acc = [h['train_balanced_acc'] for h in history]
    val_bal_acc = [h['val_balanced_acc'] for h in history]
    
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    fig.suptitle(title, fontsize=12)
    
    # Loss grafiÄŸi
    axes[0].plot(epochs, train_loss, 'b-', label='Train Loss', linewidth=2)
    axes[0].plot(epochs, val_loss, 'r-', label='Val Loss', linewidth=2)
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    axes[0].set_title('Loss EÄŸrisi')
    
    # Accuracy grafiÄŸi
    axes[1].plot(epochs, train_bal_acc, 'b-', label='Train Bal Acc', linewidth=2)
    axes[1].plot(epochs, val_bal_acc, 'r-', label='Val Bal Acc', linewidth=2)
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Balanced Accuracy')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    axes[1].set_title('Balanced Accuracy EÄŸrisi')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()


def save_model_params_excel(
    params: Dict, 
    save_path: str
) -> None:
    """
    Kaydedilen modelin tÃ¼m parametrelerini Excel'e yazar.
    
    Args:
        params: Model ve eÄŸitim parametreleri
        save_path: Excel dosya yolu
    """
    # Dict'i DataFrame'e Ã§evir (tek satÄ±r)
    df = pd.DataFrame([params])
    
    # SÃ¼tun sÄ±ralamasÄ±
    priority_cols = [
        'model_name', 'input_size', 'augmentation_level',
        'best_epoch', 'best_val_balanced_acc',
        'test_balanced_accuracy', 'test_f1_score', 
        'test_sensitivity', 'test_specificity',
        'test_accuracy', 'test_roc_auc'
    ]
    
    # Ã–ncelikli sÃ¼tunlarÄ± Ã¶ne al
    cols = [c for c in priority_cols if c in df.columns]
    cols += [c for c in df.columns if c not in cols]
    df = df[cols]
    
    df.to_excel(save_path, index=False)


# %% =====================================================
# GRAD-CAM GÃ–RSELLEÅTÄ°RME
# ========================================================

def get_gradcam_target_layer(model_name: str, model: nn.Module):
    """
    Her model mimarisi iÃ§in Grad-CAM hedef katmanÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.
    
    Hedef katman genellikle son convolutional katmandÄ±r.
    """
    model_name = model_name.lower()
    
    if model_name == "efficientnet_b1":
        return [model.features[-1]]
    elif model_name == "mobilenet_v3_large":
        return [model.features[-1]]
    elif model_name == "densenet121":
        return [model.features.denseblock4]
    elif model_name == "vgg16_bn":
        return [model.features[-1]]
    else:
        return None


def denormalize_tensor(tensor: torch.Tensor) -> np.ndarray:
    """
    Normalize edilmiÅŸ tensor'Ä± [0,1] RGB gÃ¶rÃ¼ntÃ¼ye Ã§evirir.
    
    Args:
        tensor: 3xHxW normalized tensor
    
    Returns:
        np.ndarray: HxWx3 float32 array [0,1]
    """
    if tensor.is_cuda:
        tensor = tensor.cpu()
    
    img = tensor.clone()
    mean = torch.tensor(IMAGENET_MEAN).view(3, 1, 1)
    std = torch.tensor(IMAGENET_STD).view(3, 1, 1)
    
    img = img * std + mean
    img = img.clamp(0, 1)
    img = img.permute(1, 2, 0).numpy()
    
    return img.astype(np.float32)


def run_gradcam_analysis(
    model: nn.Module,
    model_name: str,
    dataset: Dataset,
    class_names: List[str],
    device: torch.device,
    save_dir: str,
    num_samples: int = 8
) -> None:
    """
    Grad-CAM analizi yapar ve sonuÃ§larÄ± kaydeder.
    
    Args:
        model: EÄŸitilmiÅŸ model
        model_name: Model adÄ±
        dataset: Test dataset
        class_names: SÄ±nÄ±f isimleri
        device: Cihaz
        save_dir: KayÄ±t dizini
        num_samples: Ã–rnek sayÄ±sÄ±
    """
    if not GRADCAM_AVAILABLE:
        print("  âš ï¸ Grad-CAM paketi yok, atlanÄ±yor...")
        return
    
    target_layers = get_gradcam_target_layer(model_name, model)
    if target_layers is None:
        print(f"  âš ï¸ {model_name} iÃ§in Grad-CAM hedef katman bulunamadÄ±")
        return
    
    # Model'i Grad-CAM iÃ§in hazÄ±rla
    model.eval()
    for p in model.parameters():
        p.requires_grad_(True)
    
    # Grad-CAM objesi
    cam = GradCAM(model=model, target_layers=target_layers)
    
    # Rastgele Ã¶rnekler seÃ§
    n_samples = min(num_samples, len(dataset))
    indices = np.random.default_rng(42).choice(len(dataset), size=n_samples, replace=False)
    
    # KayÄ±t klasÃ¶rÃ¼
    gradcam_dir = os.path.join(save_dir, 'gradcam')
    os.makedirs(gradcam_dir, exist_ok=True)
    
    # Grid figÃ¼rÃ¼
    fig, axes = plt.subplots(2, n_samples, figsize=(3 * n_samples, 6))
    
    for i, idx in enumerate(indices):
        img_tensor, true_label = dataset[idx]
        img_input = img_tensor.unsqueeze(0).to(device)
        
        # Tahmin
        with torch.no_grad():
            logits = model(img_input)
            pred_label = logits.argmax(dim=1).item()
        
        # Grad-CAM
        grayscale_cam = cam(input_tensor=img_input)[0]
        
        # GÃ¶rselleÅŸtirme
        rgb_img = denormalize_tensor(img_tensor)
        overlay = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)
        
        # Grid'e ekle
        ax_orig = axes[0, i] if n_samples > 1 else axes[0]
        ax_cam = axes[1, i] if n_samples > 1 else axes[1]
        
        ax_orig.imshow(rgb_img)
        ax_orig.set_title(f"T:{class_names[true_label]}\nP:{class_names[pred_label]}", fontsize=9)
        ax_orig.axis('off')
        
        ax_cam.imshow(overlay)
        ax_cam.axis('off')
        
        # Tek gÃ¶rÃ¼ntÃ¼yÃ¼ kaydet
        single_path = os.path.join(gradcam_dir, f"sample_{i:02d}_T{true_label}_P{pred_label}.png")
        plt.imsave(single_path, overlay)
    
    # Grid'i kaydet
    fig.suptitle('Grad-CAM GÃ¶rselleÅŸtirmesi (Ãœst: Orijinal, Alt: CAM)', fontsize=12)
    fig.tight_layout()
    grid_path = os.path.join(gradcam_dir, 'gradcam_grid.png')
    fig.savefig(grid_path, dpi=150, bbox_inches='tight')
    plt.close(fig)
    
    print(f"  âœ“ Grad-CAM kaydedildi: {gradcam_dir}")


# %% =====================================================
# ANA EÄÄ°TÄ°M FONKSÄ°YONU
# ========================================================

def train_single_experiment(
    exp_name: str,
    model_name: str,
    input_size: int,
    aug_level: str,
    train_data: Tuple[List[str], List[int]],
    val_data: Tuple[List[str], List[int]],
    test_data: Tuple[List[str], List[int]],
    class_names: List[str],
    device: torch.device,
    output_base_dir: str
) -> Tuple[pd.DataFrame, Dict]:
    """
    Tek bir deney (model + boyut + augmentasyon kombinasyonu) iÃ§in eÄŸitim yapar.
    
    Bu fonksiyon:
    1. Model oluÅŸturur
    2. DataLoader'larÄ± hazÄ±rlar
    3. EÄŸitim dÃ¶ngÃ¼sÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±r
    4. En iyi modeli kaydeder (isimde: model_ep05_balacc0.9234_BEST.pth)
    5. Test metriklerini hesaplar
    6. TÃ¼m sonuÃ§larÄ± Excel'e yazar
    
    Args:
        exp_name: Deney adÄ±
        model_name: Model adÄ±
        input_size: GÃ¶rÃ¼ntÃ¼ boyutu
        aug_level: Augmentasyon seviyesi
        train_data: (paths, labels) tuple
        val_data: (paths, labels) tuple
        test_data: (paths, labels) tuple
        class_names: SÄ±nÄ±f isimleri
        device: Cihaz
        output_base_dir: Ã‡Ä±ktÄ± ana dizini
    
    Returns:
        Tuple[pd.DataFrame, Dict]: (epoch_history, experiment_summary)
    """
    print(f"\n{'='*60}")
    print(f"DENEY: {exp_name}")
    print(f"{'='*60}")
    
    # ===== DENEY KLASÃ–RÃœ OLUÅTUR =====
    # YapÄ±: output_dir/model_name/sz224_aug_medium/
    exp_dir = os.path.join(
        output_base_dir,
        model_name,
        f"sz{input_size}_aug_{aug_level}"
    )
    os.makedirs(exp_dir, exist_ok=True)
    print(f"ğŸ“ Ã‡Ä±ktÄ± klasÃ¶rÃ¼: {exp_dir}")
    
    # ===== VERÄ°LERÄ° HAZIRLA =====
    train_paths, train_labels = train_data
    val_paths, val_labels = val_data
    test_paths, test_labels = test_data
    
    num_classes = len(class_names)
    
    # Transforms
    train_tf, eval_tf, vis_tf = build_transforms(input_size, aug_level)
    
    # Dataset'ler
    train_dataset = ChestXRayDataset(train_paths, train_labels, transform=train_tf)
    val_dataset = ChestXRayDataset(val_paths, val_labels, transform=eval_tf)
    test_dataset = ChestXRayDataset(test_paths, test_labels, transform=eval_tf)
    
    # Weighted sampler (eÄŸitim iÃ§in)
    sampler = None
    class_counts = None
    class_weights = None
    
    if CONFIG["imbalance"]["use_weighted_sampler"]:
        sampler, class_counts, class_weights = make_weighted_sampler(train_labels, num_classes)
        print(f"ğŸ“Š SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±: {dict(zip(class_names, class_counts))}")
        print(f"ğŸ“Š SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±: {dict(zip(class_names, [f'{w:.4f}' for w in class_weights]))}")
    
    # DataLoader'lar
    batch_size = CONFIG["train"]["batch_size"]
    num_workers = CONFIG["train"]["num_workers"]
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size,
        shuffle=(sampler is None),
        sampler=sampler,
        num_workers=num_workers,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    # ===== MODEL OLUÅTUR =====
    model = build_model(model_name, num_classes=num_classes, pretrained=True)
    model = model.to(device)
    
    total_params, trainable_params = count_parameters(model)
    print(f"ğŸ”§ Model: {model_name}")
    print(f"   Toplam parametre: {total_params:,}")
    print(f"   EÄŸitilebilir: {trainable_params:,}")
    
    # ===== LOSS FONKSÄ°YONU =====
    label_smoothing = CONFIG["train"]["label_smoothing"]
    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)
    
    # ===== OPTÄ°MÄ°ZER =====
    lr = CONFIG["train"]["learning_rate"]
    weight_decay = CONFIG["train"]["weight_decay"]
    optimizer = optim.AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=lr,
        weight_decay=weight_decay
    )
    
    # ===== LEARNING RATE SCHEDULER =====
    # CosineAnnealingWarmRestarts: Periyodik olarak LR'Ä± restart eder
    scheduler_cfg = CONFIG["scheduler"]
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer,
        T_0=scheduler_cfg["T_0"],
        T_mult=scheduler_cfg["T_mult"],
        eta_min=scheduler_cfg["eta_min"]
    )
    print(f"ğŸ“ˆ LR Scheduler: CosineAnnealingWarmRestarts (T_0={scheduler_cfg['T_0']}, T_mult={scheduler_cfg['T_mult']})")
    
    # ===== MIXED PRECISION (AMP) =====
    use_amp = CONFIG["amp"]["enabled"] and device.type == "cuda"
    scaler = torch.amp.GradScaler(enabled=use_amp)
    if use_amp:
        print("âš¡ Mixed Precision (AMP) aktif")
    
    # ===== EÄÄ°TÄ°M DEÄÄ°ÅKENLERÄ° =====
    num_epochs = CONFIG["train"]["num_epochs"]
    patience = CONFIG["train"]["patience"]
    
    best_val_bal_acc = -1.0
    best_epoch = -1
    best_model_state = None
    epochs_no_improve = 0
    
    history = []  # Her epoch iÃ§in metrikler
    
    print(f"\nğŸš€ EÄŸitim baÅŸlÄ±yor ({num_epochs} epoch, patience={patience})...")
    print("-" * 80)
    
    # ===== EÄÄ°TÄ°M DÃ–NGÃœSÃœ =====
    for epoch in range(1, num_epochs + 1):
        epoch_start = time.time()
        
        # ----- TRAIN PHASE -----
        model.train()
        train_loss_sum = 0.0
        train_preds_list = []
        train_targets_list = []
        
        for batch_idx, (images, labels) in enumerate(train_loader):
            images = images.to(device)
            labels = labels.to(device)
            
            optimizer.zero_grad(set_to_none=True)
            
            # Forward pass (mixed precision)
            with torch.amp.autocast(device_type=device.type, enabled=use_amp):
                logits = model(images)
                loss = criterion(logits, labels)
            
            # Backward pass
            scaler.scale(loss).backward()
            
            scaler.step(optimizer)
            scaler.update()
            
            # Metrikler iÃ§in topla
            train_loss_sum += loss.item() * images.size(0)
            preds = logits.argmax(dim=1)
            train_preds_list.append(preds.cpu())
            train_targets_list.append(labels.cpu())
        
        # LR Scheduler step (epoch bazlÄ±)
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']
        
        # Train metrikleri
        train_loss = train_loss_sum / len(train_dataset)
        train_preds = torch.cat(train_preds_list).numpy()
        train_targets = torch.cat(train_targets_list).numpy()
        train_acc = accuracy_score(train_targets, train_preds)
        train_bal_acc = balanced_accuracy_score(train_targets, train_preds)
        
        # ----- VALIDATION PHASE -----
        model.eval()
        val_loss_sum = 0.0
        val_preds_list = []
        val_targets_list = []
        
        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(device)
                labels = labels.to(device)
                
                with torch.amp.autocast(device_type=device.type, enabled=use_amp):
                    logits = model(images)
                    loss = criterion(logits, labels)
                
                val_loss_sum += loss.item() * images.size(0)
                preds = logits.argmax(dim=1)
                val_preds_list.append(preds.cpu())
                val_targets_list.append(labels.cpu())
        
        # Val metrikleri
        val_loss = val_loss_sum / len(val_dataset)
        val_preds = torch.cat(val_preds_list).numpy()
        val_targets = torch.cat(val_targets_list).numpy()
        val_acc = accuracy_score(val_targets, val_preds)
        val_bal_acc = balanced_accuracy_score(val_targets, val_preds)
        val_f1 = f1_score(val_targets, val_preds, average='binary')
        
        epoch_time = time.time() - epoch_start
        
        # History'ye ekle
        history.append({
            'epoch': epoch,
            'train_loss': train_loss,
            'train_accuracy': train_acc,
            'train_balanced_acc': train_bal_acc,
            'val_loss': val_loss,
            'val_accuracy': val_acc,
            'val_balanced_acc': val_bal_acc,
            'val_f1': val_f1,
            'learning_rate': current_lr,
            'epoch_time_sec': epoch_time
        })
        
        # Ekrana yazdÄ±r
        print(f"Epoch {epoch:02d}/{num_epochs} | {format_time(epoch_time)} | LR: {current_lr:.2e}")
        print(f"  Train: loss={train_loss:.4f}, acc={train_acc*100:.1f}%, bal_acc={train_bal_acc*100:.1f}%")
        print(f"  Val:   loss={val_loss:.4f}, acc={val_acc*100:.1f}%, bal_acc={val_bal_acc*100:.1f}%, f1={val_f1:.3f}")
        
        # ----- EN Ä°YÄ° MODEL KONTROLÃœ -----
        if val_bal_acc > best_val_bal_acc:
            best_val_bal_acc = val_bal_acc
            best_epoch = epoch
            best_model_state = copy.deepcopy(model.state_dict())
            epochs_no_improve = 0
            
            # En iyi modeli kaydet (isimde epoch ve balanced accuracy var)
            best_filename = create_model_filename(
                model_name, epoch, val_bal_acc, input_size, aug_level, "BEST"
            )
            best_path = os.path.join(exp_dir, best_filename)
            
            # State dict kaydet
            torch.save({
                'epoch': epoch,
                'model_state_dict': best_model_state,
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'val_balanced_acc': val_bal_acc,
                'model_name': model_name,
                'input_size': input_size,
                'augmentation_level': aug_level,
                'config': CONFIG,
            }, best_path)
            
            print(f"  âœ“ YENÄ° EN Ä°YÄ°! Kaydedildi: {best_filename}")
            
            # TorchScript olarak da kaydet
            if CONFIG["output"]["save_torchscript"]:
                ts_filename = best_filename.replace('.pth', '_torchscript.pt')
                ts_path = os.path.join(exp_dir, ts_filename)
                
                model_cpu = copy.deepcopy(model).cpu().eval()
                example_input = torch.randn(1, 3, input_size, input_size)
                traced = torch.jit.trace(model_cpu, example_input)
                traced.save(ts_path)
        else:
            epochs_no_improve += 1
            print(f"  â†’ Ä°yileÅŸme yok ({epochs_no_improve}/{patience})")
        
        # Early stopping kontrolÃ¼
        if epochs_no_improve >= patience:
            print(f"\nâš ï¸ Early stopping! {patience} epoch boyunca iyileÅŸme olmadÄ±.")
            break
        
        print()
    
    print("-" * 80)
    
    # ===== EN Ä°YÄ° MODELÄ° YÃœKLE VE TEST ET =====
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    print(f"\nğŸ“Š TEST DEÄERLENDÄ°RMESÄ° (Epoch {best_epoch} modeli)")
    print("-" * 40)
    
    probs, preds, targets = predict_with_probs(model, test_loader, device, use_amp)
    test_metrics = compute_binary_metrics(probs, preds, targets)
    
    print(f"  Accuracy:         {test_metrics['accuracy']*100:.2f}%")
    print(f"  Balanced Acc:     {test_metrics['balanced_accuracy']*100:.2f}%")
    print(f"  F1 Score:         {test_metrics['f1_score']:.4f}")
    print(f"  Sensitivity:      {test_metrics['sensitivity']*100:.2f}%")
    print(f"  Specificity:      {test_metrics['specificity']*100:.2f}%")
    print(f"  ROC-AUC:          {test_metrics['roc_auc']:.4f}")
    
    # ===== CONFUSION MATRIX KAYDET =====
    if CONFIG["output"]["save_confusion_matrix"]:
        cm_path = os.path.join(exp_dir, "confusion_matrix.png")
        save_confusion_matrix_plot(
            test_metrics['confusion_matrix'],
            class_names,
            cm_path,
            title=f"{exp_name}\nTest Confusion Matrix"
        )
        print(f"  âœ“ Confusion matrix kaydedildi")
    
    # ===== EÄÄ°TÄ°M EÄRÄ°LERÄ° KAYDET =====
    if CONFIG["output"]["save_training_curves"]:
        curves_path = os.path.join(exp_dir, "training_curves.png")
        save_training_curves(history, curves_path, title=f"{exp_name} - Training Curves")
        print(f"  âœ“ Training curves kaydedildi")
    
    # ===== EPOCH LOG EXCEL KAYDET =====
    df_history = pd.DataFrame(history)
    history_excel_path = os.path.join(exp_dir, "training_log.xlsx")
    df_history.to_excel(history_excel_path, index=False)
    print(f"  âœ“ Training log kaydedildi")
    
    # ===== MODEL PARAMETRELERÄ° EXCEL KAYDET =====
    if CONFIG["output"]["export_model_params_excel"]:
        model_params = {
            'experiment_name': exp_name,
            'model_name': model_name,
            'input_size': input_size,
            'augmentation_level': aug_level,
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'batch_size': batch_size,
            'learning_rate': lr,
            'weight_decay': weight_decay,
            'label_smoothing': label_smoothing,
            'scheduler_type': scheduler_cfg["type"],
            'scheduler_T_0': scheduler_cfg["T_0"],
            'scheduler_T_mult': scheduler_cfg["T_mult"],
            'use_weighted_sampler': CONFIG["imbalance"]["use_weighted_sampler"],
            'use_amp': use_amp,
            'best_epoch': best_epoch,
            'best_val_balanced_acc': best_val_bal_acc,
            'test_accuracy': test_metrics['accuracy'],
            'test_balanced_accuracy': test_metrics['balanced_accuracy'],
            'test_f1_score': test_metrics['f1_score'],
            'test_sensitivity': test_metrics['sensitivity'],
            'test_specificity': test_metrics['specificity'],
            'test_roc_auc': test_metrics['roc_auc'],
            'test_tn': test_metrics['tn'],
            'test_fp': test_metrics['fp'],
            'test_fn': test_metrics['fn'],
            'test_tp': test_metrics['tp'],
            'train_class_counts': str(dict(zip(class_names, class_counts))) if class_counts else "N/A",
            'saved_model_path': os.path.join(exp_dir, create_model_filename(
                model_name, best_epoch, best_val_bal_acc, input_size, aug_level, "BEST"
            ))
        }
        
        params_excel_path = os.path.join(exp_dir, "model_parameters.xlsx")
        save_model_params_excel(model_params, params_excel_path)
        print(f"  âœ“ Model parameters kaydedildi")
    
    # ===== GRAD-CAM =====
    if CONFIG["gradcam"]["enabled"]:
        # GÃ¶rselleÅŸtirme iÃ§in dataset (normalize yok)
        test_vis_dataset = ChestXRayDataset(test_paths, test_labels, transform=eval_tf)
        run_gradcam_analysis(
            model, model_name, test_vis_dataset, class_names,
            device, exp_dir, CONFIG["gradcam"]["num_samples"]
        )
    
    # ===== Ã–ZET DÃ–NDÃœR =====
    summary = {
        'experiment_name': exp_name,
        'model_name': model_name,
        'input_size': input_size,
        'augmentation_level': aug_level,
        'total_params': total_params,
        'trainable_params': trainable_params,
        'best_epoch': best_epoch,
        'best_val_balanced_acc': best_val_bal_acc,
        'test_accuracy': test_metrics['accuracy'],
        'test_balanced_accuracy': test_metrics['balanced_accuracy'],
        'test_f1_score': test_metrics['f1_score'],
        'test_sensitivity': test_metrics['sensitivity'],
        'test_specificity': test_metrics['specificity'],
        'test_roc_auc': test_metrics['roc_auc'],
        'experiment_dir': exp_dir
    }
    
    return df_history, summary


# %% =====================================================
# ANA Ã‡ALIÅTIRMA FONKSÄ°YONU
# ========================================================

def main():
    """
    Ana Ã§alÄ±ÅŸtÄ±rma fonksiyonu.
    
    AdÄ±mlar:
    1. Seed'leri sabitler (reproducibility)
    2. Veriyi yÃ¼kler ve bÃ¶ler
    3. TÃ¼m deney kombinasyonlarÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r
    4. SonuÃ§larÄ± Ã¶zet Excel'e yazar
    """
    print("=" * 60)
    print("CHEST X-RAY SINIFLANDIRMA - Ã‡OKLU DENEY PIPELINE v2")
    print("=" * 60)
    print(f"BaÅŸlangÄ±Ã§ zamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ===== SEED VE CÄ°HAZ =====
    seed_everything(CONFIG["split"]["seed"])
    device = get_device()
    print()
    
    # ===== VERÄ°YÄ° YÃœKLE =====
    print("ğŸ“‚ Veri yÃ¼kleniyor...")
    paths, labels = list_images(CONFIG["dataset_root"], CONFIG["class_names"])
    print(f"   Toplam gÃ¶rÃ¼ntÃ¼: {len(paths)}")
    print(f"   SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±: {dict(zip(CONFIG['class_names'], np.bincount(labels)))}")
    print()
    
    # ===== VERÄ°YÄ° BÃ–L =====
    print("âœ‚ï¸ Veri bÃ¶lÃ¼nÃ¼yor (stratified split)...")
    split_cfg = CONFIG["split"]
    train_data, val_data, test_data = stratified_split(
        paths, labels,
        train_ratio=split_cfg["train_ratio"],
        val_ratio=split_cfg["val_ratio"],
        test_ratio=split_cfg["test_ratio"],
        seed=split_cfg["seed"]
    )
    
    print(f"   Train: {len(train_data[0])} Ã¶rnek")
    print(f"   Val:   {len(val_data[0])} Ã¶rnek")
    print(f"   Test:  {len(test_data[0])} Ã¶rnek")
    print()
    
    # ===== DENEY GRID'Ä° =====
    exp_cfg = CONFIG["experiments"]
    input_sizes = exp_cfg["input_sizes"]
    model_names = exp_cfg["models"]
    aug_levels = exp_cfg["augmentation_levels"]
    
    total_experiments = len(input_sizes) * len(model_names) * len(aug_levels)
    print(f"ğŸ§ª Toplam {total_experiments} deney Ã§alÄ±ÅŸtÄ±rÄ±lacak:")
    print(f"   Boyutlar: {input_sizes}")
    print(f"   Modeller: {model_names}")
    print(f"   Augmentasyon: {aug_levels}")
    print()
    
    # ===== Ã‡IKTI DÄ°ZÄ°NÄ° =====
    output_dir = CONFIG["output"]["save_dir"]
    os.makedirs(output_dir, exist_ok=True)
    print(f"ğŸ“ Ã‡Ä±ktÄ± dizini: {output_dir}")
    print()
    
    # ===== TÃœM DENEYLERÄ° Ã‡ALIÅTIR =====
    all_summaries = []
    all_histories = {}
    experiment_idx = 0
    
    total_start_time = time.time()
    
    for input_size in input_sizes:
        for model_name in model_names:
            for aug_level in aug_levels:
                experiment_idx += 1
                exp_name = create_experiment_name(model_name, input_size, aug_level)
                
                print(f"\n{'#'*60}")
                print(f"DENEY {experiment_idx}/{total_experiments}: {exp_name}")
                print(f"{'#'*60}")
                
                try:
                    df_history, summary = train_single_experiment(
                        exp_name=exp_name,
                        model_name=model_name,
                        input_size=input_size,
                        aug_level=aug_level,
                        train_data=train_data,
                        val_data=val_data,
                        test_data=test_data,
                        class_names=CONFIG["class_names"],
                        device=device,
                        output_base_dir=output_dir
                    )
                    
                    all_summaries.append(summary)
                    all_histories[exp_name] = df_history
                    
                except Exception as e:
                    print(f"âŒ HATA: {exp_name}")
                    print(f"   {str(e)}")
                    import traceback
                    traceback.print_exc()
    
    total_time = time.time() - total_start_time
    
    # ===== Ã–ZET EXCEL OLUÅTUR =====
    print("\n" + "=" * 60)
    print("ğŸ“Š SONUÃ‡ Ã–ZETÄ°")
    print("=" * 60)
    
    if len(all_summaries) > 0:
        df_summary = pd.DataFrame(all_summaries)
        
        # En iyi sonuÃ§lara gÃ¶re sÄ±rala
        df_summary = df_summary.sort_values(
            by=['test_balanced_accuracy', 'test_f1_score'],
            ascending=False
        ).reset_index(drop=True)
        
        # Top 5'i gÃ¶ster
        print("\nğŸ† EN Ä°YÄ° 5 DENEY (Test Balanced Accuracy'e gÃ¶re):")
        print("-" * 80)
        display_cols = [
            'experiment_name', 'best_epoch', 'best_val_balanced_acc',
            'test_balanced_accuracy', 'test_f1_score', 'test_sensitivity', 'test_specificity'
        ]
        print(df_summary.head(5)[display_cols].to_string(index=False))
        
        # Ã–zet Excel kaydet
        summary_excel_path = os.path.join(output_dir, "experiments_summary.xlsx")
        
        with pd.ExcelWriter(summary_excel_path, engine='openpyxl') as writer:
            # Ana Ã¶zet sayfasÄ±
            df_summary.to_excel(writer, sheet_name='Summary', index=False)
            
            # Her deney iÃ§in ayrÄ± sayfa (epoch loglarÄ±)
            for exp_name, df_hist in all_histories.items():
                # Excel sheet isim limiti: 31 karakter
                sheet_name = exp_name[:31]
                df_hist.to_excel(writer, sheet_name=sheet_name, index=False)
        
        print(f"\nâœ… Ã–zet Excel kaydedildi: {summary_excel_path}")
    
    print(f"\nâ±ï¸ Toplam sÃ¼re: {format_time(total_time)}")
    print(f"ğŸ“… BitiÅŸ zamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\nâœ… TÃ¼m deneyler tamamlandÄ±!")


# %% =====================================================
# Ã‡ALIÅTIR
# ========================================================

if __name__ == "__main__":
    main()
